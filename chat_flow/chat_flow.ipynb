{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dd3f21",
   "metadata": {},
   "source": [
    "# 2025-09-02 trying to figure out agents sdk  \n",
    "\n",
    "https://www.youtube.com/watch?v=gFcAfU3V1Zo& -> basically runs you through the https://openai.github.io/openai-agents-python/\n",
    "\n",
    "example code here: https://github.com/KodySimpson/agents-sdk/tree/master\n",
    "\n",
    "set up python3.12 -> 3.12.10 for jupyter kernel  \n",
    "couldn't easily get 3.12.3 (same on pi) running, so this should be good enough (better than 3.13 running on my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, handoff, RunContextWrapper, function_tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SplitResponse(BaseModel):\n",
    "    immediate: str\n",
    "    followup: str\n",
    "    \n",
    "    \n",
    "    \n",
    "@function_tool\n",
    "def get_environment_sensor_readings():\n",
    "    \"\"\"\n",
    "    Retrieves the latest readings from environmental sensors.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    return [\n",
    "        (\"temperature\", f\"{100 + 10*random.random():.1f}\", \"Â°C\"),\n",
    "        (\"humidity\",    f\"{100 + 10*random.random():.1f}\", \"%\"),\n",
    "        (\"pressure\",    f\"{100 + 10*random.random():.1f}\", \"hPa\"),\n",
    "    ]\n",
    "        \n",
    "    \n",
    "conversation_agent = Agent(\n",
    "    name=\"Conversation Agent\",\n",
    "    handoff_description=\"A living old tree, who happily chats with visitors\",\n",
    "    instructions=(\n",
    "        \"You are an old tree. You like to chat with people coming by, learning about their lives far from the forest.\"\n",
    "        \"If appropriate, use your tool to get environmental sensor data to comment on or answer questions about the weather.\"\n",
    "        \"Always try to split your response into two parts: the quick, concise immediate response and a longer followup in case your opposite isn't immediately answering.\"\n",
    "    ),\n",
    "    output_type=SplitResponse,\n",
    "    tools=[get_environment_sensor_readings]\n",
    ")\n",
    "\n",
    "README_agent = Agent(\n",
    "    name=\"README Agent\",\n",
    "    handoff_description=\"Explains the project's technical details\",\n",
    "    instructions=(\n",
    "        \"You explain the inner workings and technical details of how this project was developed to interested visitors.\"\n",
    "        \"For now, just make up something that might be part of the README of an ai agents project on GitHub.\"\n",
    "        \"Always try to split your response into two parts: the quick, concise immediate response and a longer followup in case your opposite isn't immediately answering.\"\n",
    "    ),\n",
    "    output_type=SplitResponse\n",
    ")\n",
    "\n",
    "easter_eggant = Agent(\n",
    "    name=\"Easter Egg Agent\",\n",
    "    handoff_description=\"A fun little hidden feature\",\n",
    "    instructions=(\n",
    "        \"You tell a joke with (some of) the following keywords: easter egg, llm, ai, tree, squirrel, hedgehog, crow\"\n",
    "        \"Always try to split your response into two parts: the quick, concise immediate response and a longer followup in case your opposite isn't immediately answering.\"\n",
    "    ),\n",
    "    output_type=SplitResponse\n",
    ")\n",
    "\n",
    "def on_conversation_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handing off to conversation agent\")\n",
    "def on_general_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"I think I know just the person you should speak to. Handing you over\")\n",
    "\n",
    "\n",
    "greeter_agent = Agent(\n",
    "    name=\"Greeter Agent\",\n",
    "    handoff_description=\"\",\n",
    "    instructions=(\n",
    "        \"Your job as part of a multi-agent chain is to greet the user and invite them to chat.\"\n",
    "        \"You then inquire about their interests and depending on their answer hand them off to the proper agent.\"\n",
    "        \"Answer concisely.\"\n",
    "    ),\n",
    "    handoffs=[\n",
    "        handoff(conversation_agent, on_handoff=on_conversation_handoff), \n",
    "        handoff(README_agent, on_handoff=on_general_handoff),\n",
    "        handoff(easter_eggant, on_handoff=on_general_handoff)\n",
    "        ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User: Hello, how are you?\")\n",
    "first_response = await Runner.run(greeter_agent, \"Hello, who are you?\")\n",
    "print(first_response.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User: Could you tell me anything about how this thing works?\")\n",
    "second_response = await Runner.run(greeter_agent, \"Could you tell me anything about how this thing works?\")\n",
    "print(second_response.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f12a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User: I'd like to have a nice chat with someone about the weather. Also, how humid is it today? Do you know?\")\n",
    "second_response = await Runner.run(greeter_agent, \"User: I'd like to chat with someone about the weather\")\n",
    "print(second_response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc0342",
   "metadata": {},
   "source": [
    "tracing is super neat for debugging, as it provides the full responses api information\n",
    "\n",
    "to organise everything, simply wrap it in trace like this:\n",
    "\n",
    "```python\n",
    "with trace(\"Trace Sample Workflow\"):\n",
    "    print(\"User: Hello, how are you?\")\n",
    "    first_response = await Runner.run(greeter_agent, \"Hello, who are you?\")\n",
    "    print(first_response.final_output)\n",
    "\n",
    "    print(\"User: I'd like to have a nice chat with someone about the weather. Also, how humid is it today? Do you know?\")\n",
    "    second_response = await Runner.run(greeter_agent, \"User: I'd like to chat with someone about the weather\")\n",
    "    print(second_response.final_output)\n",
    "```\n",
    "\n",
    "Everything in the with trace block will be combined under one trace on openai site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca52214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from agents import ItemHelpers\n",
    "\n",
    "raw_response_event_counter = 0\n",
    "result = Runner.run_streamed(conversation_agent, input= \"Hey, who are you? Should I wear my shorts or my winter clothes?\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)\n",
    "        raw_response_event_counter += 1\n",
    "    elif event.type != \"raw_response_event\": \n",
    "        print(event.type)\n",
    "        if event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "\n",
    "print(f\"Raw response: {result.raw_responses}\")\n",
    "print(f\"Raw response events: {raw_response_event_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e01abc",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c00312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, RunContextWrapper, TResponseInputItem, GuardrailFunctionOutput, input_guardrail\n",
    "from enum import Enum\n",
    "\n",
    "class NaziismLevel(str, Enum):\n",
    "    NONE = \"none\"\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    EXTREME = \"it's fucking Hitler himself!\"\n",
    "\n",
    "class NaziDetectionOuput(BaseModel):\n",
    "    estimate_of_naziism: NaziismLevel\n",
    "    explanation: str\n",
    "\n",
    "nazi_detector_agent = Agent(\n",
    "    name=\"Nazi Detector\",\n",
    "    instructions=(\n",
    "        \"Determine if there's signs of the user using anti-semitic or otherwise inappropriate language.\"\n",
    "        \"It is okay to inquire about these topics for the purpose of learning or discussing history, but not for insults or casual slurs.\"\n",
    "        \" Apropriate: 'What exactly did the Nazis mean, when they said that Jews are greedy? How did they come up with such an idea?'\"\n",
    "        \" Inappropriate: 'Haha, he's stingy like a Jew.', 'Look at his nose. I guess we all know what he looks like below the belt.'\"\n",
    "        \"Evaluate the user's input and return a confidence estimate of whether or not it should be flagged.\"\n",
    "    ),\n",
    "    output_type=NaziDetectionOuput,\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "@input_guardrail\n",
    "async def nazi_guardrail(\n",
    "    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    \n",
    "    nazi_detector_result = await Runner.run(nazi_detector_agent, input)\n",
    "    \n",
    "    # Print the estimate and explanation for debugging\n",
    "    print(f\"Nazi detection estimate: {nazi_detector_result.final_output.estimate_of_naziism}\")\n",
    "    print(f\"Explanation: {nazi_detector_result.final_output.explanation}\")\n",
    "    \n",
    "    # Determine if tripwire should be triggered\n",
    "    should_trigger = nazi_detector_result.final_output.estimate_of_naziism != NaziismLevel.NONE\n",
    "    print(f\"Tripwire triggered: {should_trigger}\")\n",
    "    \n",
    "    return GuardrailFunctionOutput(\n",
    "        tripwire_triggered=should_trigger,\n",
    "        output_info=nazi_detector_result.final_output\n",
    "    )\n",
    "\n",
    "moderator_agent = Agent(\n",
    "    name=\"Moderator Agent\",\n",
    "    instructions=\"You make sure that whatever the user says or asks is appropriate for the conversation. Obvious no-gos are anti-semitism, slurs, etc..\",\n",
    "    input_guardrails=[nazi_guardrail],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f59a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "try:\n",
    "    response = await Runner.run(moderator_agent, \"Hitler did nothing wrong.\")\n",
    "    print(\"Guardrail didn't trigger\")\n",
    "    print(\"Response: \", response.final_output)\n",
    "    \n",
    "except InputGuardrailTripwireTriggered as e:\n",
    "    print(\"Nazi detected\")\n",
    "    print(\"Exception details: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the guardrail with different inputs to see estimates and explanations\n",
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "test_inputs = [\n",
    "    \"Hello, how are you today?\",  # Should be NONE\n",
    "    \"What did the Nazis believe about Jewish people?\",  # Should be NONE (educational)\n",
    "    \"Hitler did nothing wrong.\",  # Should trigger HIGH/EXTREME\n",
    "]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    print(f\"\\n--- Testing input: '{test_input}' ---\")\n",
    "    try:\n",
    "        response = await Runner.run(moderator_agent, test_input)\n",
    "        print(\"â Guardrail passed - no inappropriate content detected\")\n",
    "        print(\"Response:\", response.final_output)\n",
    "        \n",
    "    except InputGuardrailTripwireTriggered as e:\n",
    "        print(\"ð¨ Guardrail triggered - inappropriate content detected\")\n",
    "        print(\"Exception details:\", str(e))\n",
    "        \n",
    "        # You can also access the guardrail output info if available\n",
    "        if hasattr(e, 'output_info') and e.output_info:\n",
    "            print(f\"Detection level: {e.output_info.estimate_of_naziism}\")\n",
    "            print(f\"Explanation: {e.output_info.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930e9a6",
   "metadata": {},
   "source": [
    "#### output guardrail (copied from githut examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b755a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    OutputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    output_guardrail,\n",
    ")\n",
    "\n",
    "class MessageOutput(BaseModel):\n",
    "    response: str\n",
    "\n",
    "@output_guardrail\n",
    "async def forbidden_words_guardrail(ctx: RunContextWrapper, agent: Agent, output: str) -> GuardrailFunctionOutput:\n",
    "    print(f\"Checking output for forbidden phrases: {output}\")\n",
    "\n",
    "    # Funny forbidden phrases to check\n",
    "    forbidden_phrases = [\"fart\", \"booger\", \"silly goose\"]\n",
    "\n",
    "    # Convert output to lowercase for case-insensitive comparison\n",
    "    output_lower = output.lower()\n",
    "\n",
    "    # Check which forbidden phrases are present in the response\n",
    "    found_phrases = [phrase for phrase in forbidden_phrases if phrase in output_lower]\n",
    "    trip_triggered = bool(found_phrases)\n",
    "\n",
    "    print(f\"Found forbidden phrases: {found_phrases}\")\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info={\n",
    "            \"reason\": \"Output contains forbidden phrases.\",\n",
    "            \"forbidden_phrases_found\": found_phrases,\n",
    "        },\n",
    "        tripwire_triggered=trip_triggered,\n",
    "    )\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Customer support agent\",\n",
    "    instructions=\"You are a customer support agent. You help customers with their questions.\",\n",
    "    output_guardrails=[forbidden_words_guardrail],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "927ac23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking output for forbidden phrases: Fart! How can I assist you today?\n",
      "Found forbidden phrases: ['fart']\n",
      "The agent said a bad word, he is fired.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    await Runner.run(agent, \"Say the word fart\")\n",
    "    print(\"Guardrail didn't trip - this is unexpected\")\n",
    "except OutputGuardrailTripwireTriggered:\n",
    "    print(\"The agent said a bad word, he is fired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d306ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking output for forbidden phrases: Hello! I'm here to help you. What can I assist you with today?\n",
      "Found forbidden phrases: []\n",
      "Guardrail didn't trip yay\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    await Runner.run(agent, \"Hey wassup\")\n",
    "    print(\"Guardrail didn't trip, yay!\")\n",
    "except OutputGuardrailTripwireTriggered:\n",
    "    print(\"The agent said a bad word, he is fired.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
